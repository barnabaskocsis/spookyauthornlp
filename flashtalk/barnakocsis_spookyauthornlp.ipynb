{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "barnakocsis_spookyauthornlp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bAZYy7kYB1hg",
        "0J5jVZIS9s7K",
        "cKx-qSRhLc6n",
        "JITtv6vt4cUB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-5TdNEW5Tw6"
      },
      "source": [
        "# **Spooky Author Identification - Sequence classification with NLP**\n",
        "\n",
        "# **Description of the task:**\n",
        "\n",
        "As I scurried across the candlelit chamber, manuscripts in hand, I thought I'd made it. Nothing would be able to hurt me anymore. Little did I know there was one last fright lurking around the corner.\n",
        "\n",
        "DING! My phone pinged me with a disturbing notification. It was Will, the scariest of Kaggle moderators, sharing news of another data leak.\n",
        "\n",
        "\"ph’nglui mglw’nafh Cthulhu R’lyeh wgah’nagl fhtagn!\" I cried as I clumsily dropped my crate of unbound, spooky books. Pages scattered across the chamber floor. How will I ever figure out how to put them back together according to the authors who wrote them? Or are they lost, forevermore? Wait, I thought... I know, machine learning!\n",
        "\n",
        "In this year's Halloween playground competition, you're challenged to predict the author of excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft.\n",
        "\n",
        "---\n",
        "\n",
        "The notebook uses GloVe developed by Stanford NLP researchers and included in the StanfordNLP software package.\n",
        "\n",
        "This example will teach you how to:\n",
        "\n",
        "\n",
        "1.   Preprocess data for sequence classiification\n",
        "2.   Create a word embeddings matrix from a pre-trained GloVe model\n",
        "3.   Train a single layer LSTM model and a Bidirectional LSTM model\n",
        "\n",
        "After the example you will be tasked to **complete exercises** relevant to the notebook.\n",
        "\n",
        "\n",
        "For further reading:\n",
        "\n",
        "* StanfordNLP: https://stanfordnlp.github.io/\n",
        "* GloVe: https://nlp.stanford.edu/pubs/glove.pdf\n",
        "* LSTM and GRU: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310dOj4Y73zI"
      },
      "source": [
        "# **About the authors**\n",
        "\n",
        "   **EAP - [Edgar Allen Poe](https://en.wikipedia.org/wiki/Edgar_Allan_Poe)** : American writer who wrote poetry and short stories that revolved around tales of mystery and the grisly and the grim. Arguably his most famous work is the poem - \"The Raven\" and he is also widely considered the pioneer of the genre of the detective fiction.\n",
        "\n",
        "   **HPL - [H.P. Lovecraft](https://en.wikipedia.org/wiki/H._P._Lovecraft)** : Best known for authoring works of horror fiction, the stories that he is most celebrated for revolve around the fictional mythology of the infamous creature \"Cthulhu\" - a hybrid chimera mix of Octopus head and humanoid body with wings on the back.\n",
        "\n",
        "   **MWS - [Mary Shelley](https://en.wikipedia.org/wiki/Mary_Shelley)** : Seemed to have been involved in a whole panoply of literary pursuits - novelist, dramatist, travel-writer, biographer. She is most celebrated for the classic tale of Frankenstein where the scientist Frankenstein a.k.a \"The Modern Prometheus\" creates the Monster that comes to be associated with his name.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAZYy7kYB1hg"
      },
      "source": [
        "# **Import data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWyWeak6ZP7g"
      },
      "source": [
        "In order to download the dataset for the exercise you have to register an account on Kaggle (https://www.kaggle.com/), alternatively you can use a Google account for this step. \n",
        "\n",
        "After you have done that you can download the dataset via this link:\n",
        "https://www.kaggle.com/c/spooky-author-identification/download/train.zip\n",
        "\n",
        "Then you need to upload this file to Google Colab,by opening the **Table of contents** tab on the left side, then choose **Files** on the same line and press the  **Upload** button.\n",
        "\n",
        "After you have done this, running the following cell is going to unzip the training dataset and download the pre-trained GloVe embedding created by Stanford.\n",
        "\n",
        "If you don't see the newly created files,please press **Refresh** under **Files**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hlPSyyVpn2g",
        "outputId": "6532c675-ec74-43c3-a5bb-80bc785e84ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import requests, zipfile, io\n",
        "\n",
        "print(\"Unzipping the training dataset...\")\n",
        "\n",
        "z = zipfile.ZipFile(\"/content/train.zip\")\n",
        "z.extractall()\n",
        "\n",
        "print(\"Downloading pre-trained GloVe embedding...\")\n",
        "\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "r = requests.get(url)\n",
        "\n",
        "print(\"Unzipping pre-trained GloVe embedding...\")\n",
        "\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extract(\"glove.6B.50d.txt\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping the training dataset...\n",
            "Downloading pre-trained GloVe embedding...\n",
            "Unzipping pre-trained GloVe embedding...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/glove.6B.50d.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV758M0T9gPT"
      },
      "source": [
        "# **A look at the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnlRhKce-Fqa"
      },
      "source": [
        "## **First let's see the most commonly used words of the authors:**\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/barnabaskocsis/spookyauthornlp/master/eap_raven_wordcloud.png)\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/barnabaskocsis/spookyauthornlp/master/hpl_cthulhu_wordcloud.png)\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/barnabaskocsis/spookyauthornlp/master/mws_frankenstein_wordcloud.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li8GevAO_s-6"
      },
      "source": [
        "## **Read data**\n",
        "\n",
        "We use pandas to read the .csv file provided which contains the text data and the corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ9Krd-OmMfz"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/content/train.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUYQGLcGmcVP",
        "outputId": "026aa4ba-8a8a-4fa0-f4c6-25fa13295df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f63723d-30e4-475d-9b43-99991c08904f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f63723d-30e4-475d-9b43-99991c08904f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f63723d-30e4-475d-9b43-99991c08904f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f63723d-30e4-475d-9b43-99991c08904f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J5jVZIS9s7K"
      },
      "source": [
        "# Theory behind GloVe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYl8ZC1t92Xn"
      },
      "source": [
        "GloVe (Global Vectors for Word Representation) is a tool released by Stanford NLP Group researchers Jeffrey Pennington, Richard Socher, and Chris Manning for learning continuous-space vector representations of words.\n",
        "\n",
        "The GloVe model learns word vectors by examining word co-occurrences within a text corpus. Before the training of the actual model, a co-occurence matrix need to be constructed where each cell, represents how often a word appears in the context on another.\n",
        "\n",
        "We run through our corpus just once to build the matrix and from then on use this co-occurrence data in place of the actual corpus.\n",
        "\n",
        "Let the co-occurrence matrix be $X$.\n",
        "\n",
        "For each word pair of word $i$ and word $j$:\n",
        "\n",
        "$$w_i^Tw_j+b_i+b_j = log X_{ij}$$\n",
        "\n",
        "where $b_i$ and $b_j$ are scalar bias terms.\n",
        "\n",
        "We want to build word vectors that retain some useful information about how every pair of words $i$ and $j$ co-occur. We’ll do this by minimizing an objective function $J$, which evaluates the sum of all squared errors based on the above equation, weighted with a function $f$:\n",
        "\n",
        "$$J = \\displaystyle\\sum_{i=1}^V \\sum_{j=1}^V f(X_{ij}) (w_i^Tw_j+b_i+b_j)$$\n",
        "\n",
        "where we choose an $f$ that prevents common words from skewing our objective too much.\n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Le-Lu-9/publication/303376372/figure/fig6/AS:668376489816091@1536364781736/Example-words-embedded-in-the-vector-space-using-word-to-vector-modeling.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdVEUdf36fWm"
      },
      "source": [
        "# **Text Preprocessing and embedding matrix initialization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4RzGPa0GMbf"
      },
      "source": [
        "Using LabelEncoder from sklearn we transform our text labels to numbers for the neural network and split our data into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU9BMgc2mciA"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "labels = le.fit_transform(train.author.values) #EAP 0 HPL 1 MWS 2\n",
        "data = train.text.values\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, shuffle=True, stratify=labels)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXuri5QGnVJf",
        "outputId": "3a56d12a-ae2e-458d-ace3-2e62e618d7da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "print(\"\\n\")\n",
        "print(\"Sample train: \" + x_train[1])\n",
        "print(\"Sample validation: \" + x_val[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17621,)\n",
            "(17621,)\n",
            "(1958,)\n",
            "(1958,)\n",
            "\n",
            "\n",
            "Sample train: they wanted to mix like they done with the Kanakys, an' he fer one didn't feel baound to stop 'em.\n",
            "Sample validation: Most philosophers, upon many points of philosophy, are still very unphilosophical.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4ZI9UGkHi7N"
      },
      "source": [
        "We create an embeddings index dictionary from the pre-trained GloVe model containing 6 billion tokens in 50 dimensional vectors, the keys are words and the values are vectors. This contains all words our model will know."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq_PzOJvnW6Q",
        "outputId": "f776a62e-8816-484d-c9e5-b05867c16fb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(\"/content/glove.6B.50d.txt\",'r') as file:\n",
        "  for line in file:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "    \n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "print(list(embeddings_index.items())[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n",
            "('the', array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
            "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
            "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
            "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
            "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
            "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
            "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
            "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
            "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
            "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
            "      dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djGs625cJ0XP"
      },
      "source": [
        "Now we have to create an embedding matrix from our embeddings index for weights used by the keras embeddings layer later.\n",
        "\n",
        "The Keras preprocessing library contains the Tokenizer we are going to use. This is going to vectorize our text by creating a dictionary containing all the words in our data and outputting each as a sequence of integers where every integer represent a word in the dictionary.\n",
        "\n",
        "After this we need to pad our sequences for the Recurrent Neural Network, we set the target sentence length to 50, sequences longer will be truncated, sequences shorter are padded with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBC8FlxunW9i",
        "outputId": "a1ffda73-65d2-4cbf-8354-cfcfb406e4e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing import sequence, text\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=None)\n",
        "max_sent_len = 50\n",
        "\n",
        "tokenizer.fit_on_texts(list(x_train) + list(x_val))\n",
        "\n",
        "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
        "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "x_train_pad = sequence.pad_sequences(x_train_seq, maxlen=max_sent_len)\n",
        "x_val_pad = sequence.pad_sequences(x_val_seq, maxlen=max_sent_len)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(\"Train sample data:\" )\n",
        "print(x_train[1])\n",
        "print(x_train_seq[1])\n",
        "print(\"\\n\")\n",
        "print(x_train_pad[1])\n",
        "print(\"\\n\")\n",
        "print(\"Validation sample data:\" )\n",
        "print(x_val[1])\n",
        "print(x_val_seq[1])\n",
        "print(\"\\n\")\n",
        "print(x_val_pad[1])\n",
        "print(\"\\n\")\n",
        "print(list(word_index.items())[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sample data:\n",
            "they wanted to mix like they done with the Kanakys, an' he fer one didn't feel baound to stop 'em.\n",
            "[43, 2353, 4, 10108, 82, 43, 339, 14, 1, 5390, 252, 13, 2195, 38, 2112, 302, 16051, 4, 2032, 1299]\n",
            "\n",
            "\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0    43  2353     4 10108    82    43\n",
            "   339    14     1  5390   252    13  2195    38  2112   302 16051     4\n",
            "  2032  1299]\n",
            "\n",
            "\n",
            "Validation sample data:\n",
            "Most philosophers, upon many points of philosophy, are still very unphilosophical.\n",
            "[86, 4321, 44, 113, 1123, 2, 1395, 56, 104, 60, 12261]\n",
            "\n",
            "\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0    86  4321    44   113  1123     2  1395    56   104\n",
            "    60 12261]\n",
            "\n",
            "\n",
            "[('the', 1), ('of', 2), ('and', 3), ('to', 4), ('a', 5), ('i', 6), ('in', 7), ('was', 8), ('that', 9), ('my', 10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rfQY1AcP_3P"
      },
      "source": [
        "The labels have to be one-hot encoded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blCPJN3PsXhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e275a04-5835-420f-830c-ac4175918b21"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "y_train_cat = np_utils.to_categorical(y_train)\n",
        "y_val_cat = np_utils.to_categorical(y_val)\n",
        "\n",
        "print(\"Authors:\")\n",
        "print(y_train_cat)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authors:\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1uvjPdHQBMc"
      },
      "source": [
        "Here we create the embedding matrix as a numpy array, the dimensions are the number of words in our dictionary and the length of our word embedding vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZfIqnKusXqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e1312e-ef2e-47ae-af45-d2d497982050"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in the embedding index will be all-zeros\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(\"The word 'the': \\n\")\n",
        "print(\"Embedding index: \\n\")\n",
        "print(embeddings_index.get(\"the\"))\n",
        "print(\"\\nEmbedding matrix: \\n\")\n",
        "print(embedding_matrix[1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'the': \n",
            "\n",
            "Embedding index: \n",
            "\n",
            "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n",
            "\n",
            "Embedding matrix: \n",
            "\n",
            "[ 4.18000013e-01  2.49679998e-01 -4.12420005e-01  1.21699996e-01\n",
            "  3.45270008e-01 -4.44569997e-02 -4.96879995e-01 -1.78619996e-01\n",
            " -6.60229998e-04 -6.56599998e-01  2.78430015e-01 -1.47670001e-01\n",
            " -5.56770027e-01  1.46579996e-01 -9.50950012e-03  1.16579998e-02\n",
            "  1.02040000e-01 -1.27920002e-01 -8.44299972e-01 -1.21809997e-01\n",
            " -1.68009996e-02 -3.32789987e-01 -1.55200005e-01 -2.31309995e-01\n",
            " -1.91809997e-01 -1.88230002e+00 -7.67459989e-01  9.90509987e-02\n",
            " -4.21249986e-01 -1.95260003e-01  4.00710011e+00 -1.85939997e-01\n",
            " -5.22870004e-01 -3.16810012e-01  5.92130003e-04  7.44489999e-03\n",
            "  1.77780002e-01 -1.58969998e-01  1.20409997e-02 -5.42230010e-02\n",
            " -2.98709989e-01 -1.57490000e-01 -3.47579986e-01 -4.56370004e-02\n",
            " -4.42510009e-01  1.87849998e-01  2.78489990e-03 -1.84110001e-01\n",
            " -1.15139998e-01 -7.85809994e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FluZkUJLJzQG"
      },
      "source": [
        "# **Single layer LSTM Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvduewmYz_Iu"
      },
      "source": [
        "Our single layer model consists of an Embedding layer which outputs a 3D tensor with shape (batch_size, sequence_length, output_dim),this is the input for the LSTM layer. We use our embedding matrix as weights, which we created previously from the GloVe embedding and set the trainable property of the Embedding layer to False to prevent it from changing the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "8c269632-fc8c-4631-f5fe-94f2e47a78d8",
        "id": "kNaa5L7oEmoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = len(word_index) + 1,\n",
        "                    output_dim = 50,\n",
        "                    weights = [embedding_matrix],\n",
        "                    input_length = max_sent_len,\n",
        "                    trainable = False))\n",
        "model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            1297200   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               91648     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,389,235\n",
            "Trainable params: 92,035\n",
            "Non-trainable params: 1,297,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "e15574f4-69af-40a6-bd2c-a36bcdb20f78",
        "id": "eMWQAk0UEmoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
        "\n",
        "model.fit(x_train_pad, y_train_cat, batch_size=256, epochs=100, \n",
        "          verbose=1, validation_data=(x_val_pad, y_val_cat), callbacks=[earlystop])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 32s 392ms/step - loss: 0.9677 - accuracy: 0.5261 - val_loss: 0.8711 - val_accuracy: 0.6124\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 27s 384ms/step - loss: 0.8687 - accuracy: 0.6020 - val_loss: 0.8373 - val_accuracy: 0.6210\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 26s 384ms/step - loss: 0.8395 - accuracy: 0.6218 - val_loss: 0.8136 - val_accuracy: 0.6364\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 27s 388ms/step - loss: 0.8273 - accuracy: 0.6249 - val_loss: 0.7961 - val_accuracy: 0.6456\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 27s 387ms/step - loss: 0.8127 - accuracy: 0.6398 - val_loss: 0.7992 - val_accuracy: 0.6466\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 27s 386ms/step - loss: 0.7920 - accuracy: 0.6484 - val_loss: 0.7839 - val_accuracy: 0.6502\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 27s 384ms/step - loss: 0.7767 - accuracy: 0.6555 - val_loss: 0.7831 - val_accuracy: 0.6486\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 26s 379ms/step - loss: 0.7583 - accuracy: 0.6656 - val_loss: 0.7576 - val_accuracy: 0.6685\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 26s 379ms/step - loss: 0.7448 - accuracy: 0.6748 - val_loss: 0.7542 - val_accuracy: 0.6706\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 26s 381ms/step - loss: 0.7298 - accuracy: 0.6834 - val_loss: 0.7503 - val_accuracy: 0.6747\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 26s 380ms/step - loss: 0.7227 - accuracy: 0.6840 - val_loss: 0.7531 - val_accuracy: 0.6624\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 27s 386ms/step - loss: 0.7139 - accuracy: 0.6935 - val_loss: 0.7468 - val_accuracy: 0.6726\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 27s 388ms/step - loss: 0.6992 - accuracy: 0.7012 - val_loss: 0.7391 - val_accuracy: 0.6895\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 26s 381ms/step - loss: 0.6897 - accuracy: 0.7038 - val_loss: 0.7226 - val_accuracy: 0.6987\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 26s 380ms/step - loss: 0.6797 - accuracy: 0.7099 - val_loss: 0.7156 - val_accuracy: 0.6931\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 26s 376ms/step - loss: 0.6622 - accuracy: 0.7191 - val_loss: 0.7072 - val_accuracy: 0.7028\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 26s 375ms/step - loss: 0.6527 - accuracy: 0.7223 - val_loss: 0.7152 - val_accuracy: 0.6951\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 26s 375ms/step - loss: 0.6466 - accuracy: 0.7245 - val_loss: 0.6983 - val_accuracy: 0.7012\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 26s 374ms/step - loss: 0.6412 - accuracy: 0.7266 - val_loss: 0.6933 - val_accuracy: 0.7089\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 26s 376ms/step - loss: 0.6255 - accuracy: 0.7325 - val_loss: 0.6991 - val_accuracy: 0.6992\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 26s 379ms/step - loss: 0.6158 - accuracy: 0.7382 - val_loss: 0.7058 - val_accuracy: 0.7028\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 26s 377ms/step - loss: 0.6065 - accuracy: 0.7462 - val_loss: 0.6908 - val_accuracy: 0.7038\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 27s 389ms/step - loss: 0.6049 - accuracy: 0.7442 - val_loss: 0.7036 - val_accuracy: 0.7114\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 27s 392ms/step - loss: 0.5958 - accuracy: 0.7460 - val_loss: 0.6910 - val_accuracy: 0.7043\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 26s 381ms/step - loss: 0.5943 - accuracy: 0.7537 - val_loss: 0.6905 - val_accuracy: 0.7145\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 26s 380ms/step - loss: 0.5831 - accuracy: 0.7560 - val_loss: 0.6898 - val_accuracy: 0.7160\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 26s 380ms/step - loss: 0.5759 - accuracy: 0.7617 - val_loss: 0.7085 - val_accuracy: 0.7125\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 26s 380ms/step - loss: 0.5694 - accuracy: 0.7602 - val_loss: 0.7076 - val_accuracy: 0.7196\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 26s 376ms/step - loss: 0.5645 - accuracy: 0.7624 - val_loss: 0.6877 - val_accuracy: 0.7155\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 26s 379ms/step - loss: 0.5520 - accuracy: 0.7712 - val_loss: 0.7084 - val_accuracy: 0.7053\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 27s 385ms/step - loss: 0.5626 - accuracy: 0.7632 - val_loss: 0.6992 - val_accuracy: 0.7181\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 26s 380ms/step - loss: 0.5422 - accuracy: 0.7770 - val_loss: 0.6865 - val_accuracy: 0.7181\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 26s 383ms/step - loss: 0.5497 - accuracy: 0.7730 - val_loss: 0.6965 - val_accuracy: 0.7145\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 27s 387ms/step - loss: 0.5296 - accuracy: 0.7804 - val_loss: 0.7239 - val_accuracy: 0.7109\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 26s 383ms/step - loss: 0.5266 - accuracy: 0.7835 - val_loss: 0.7251 - val_accuracy: 0.7017\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 26s 377ms/step - loss: 0.5228 - accuracy: 0.7842 - val_loss: 0.7169 - val_accuracy: 0.7155\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 27s 386ms/step - loss: 0.5122 - accuracy: 0.7869 - val_loss: 0.7061 - val_accuracy: 0.7114\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7eb0023d50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "c54b816d-f578-4423-f734-d402a223f72c",
        "id": "5uQopcWpEmoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(x_val_pad, y_val_cat, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7060660719871521\n",
            "Test accuracy: 0.7114402651786804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "046c5123-1280-4cc7-d784-cb7deda3d621",
        "id": "4VP4eMe8Emot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preds = model.predict(x_val_pad)\n",
        "print(x_val_pad)\n",
        "print(preds[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0 ...  1700    25  9854]\n",
            " [    0     0     0 ...    35 24931  3080]\n",
            " [    0     0     0 ...     2    55  4243]\n",
            " ...\n",
            " [    0     0     0 ...    19     5  4008]\n",
            " [    0     0     0 ...  1320     3  5364]\n",
            " [    0     0     0 ...     2    29   221]]\n",
            "[0.94635147 0.0451295  0.00851901]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKx-qSRhLc6n"
      },
      "source": [
        "# **Bidirectional LSTM Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "46a3f5fd-c531-4ac9-ad51-f620dcae7b5b",
        "id": "CjVr-vKPLotG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = len(word_index) + 1,\n",
        "                    output_dim = 50,\n",
        "                    weights = [embedding_matrix],\n",
        "                    input_length = max_sent_len,\n",
        "                    trainable = False))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 50)            1297200   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 256)               183296    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 1,481,267\n",
            "Trainable params: 184,067\n",
            "Non-trainable params: 1,297,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn-mrmZXHIVc",
        "outputId": "d172fef6-bc56-4953-dd49-68f5a74aa78f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1780
        }
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
        "\n",
        "model.fit(x_train_pad, y_train_cat, batch_size=256, epochs=100, \n",
        "          verbose=1, validation_data=(x_val_pad, y_val_cat), callbacks=[earlystop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17621 samples, validate on 1958 samples\n",
            "Epoch 1/100\n",
            "17621/17621 [==============================] - 13s 759us/step - loss: 0.9926 - acc: 0.5055 - val_loss: 0.8546 - val_acc: 0.6251\n",
            "Epoch 2/100\n",
            "17621/17621 [==============================] - 12s 668us/step - loss: 0.9209 - acc: 0.5613 - val_loss: 0.8895 - val_acc: 0.5766\n",
            "Epoch 3/100\n",
            "17621/17621 [==============================] - 12s 673us/step - loss: 0.9043 - acc: 0.5785 - val_loss: 0.8370 - val_acc: 0.6328\n",
            "Epoch 4/100\n",
            "17621/17621 [==============================] - 12s 668us/step - loss: 0.8844 - acc: 0.5930 - val_loss: 0.7967 - val_acc: 0.6583\n",
            "Epoch 5/100\n",
            "17621/17621 [==============================] - 12s 667us/step - loss: 0.8670 - acc: 0.6001 - val_loss: 0.8181 - val_acc: 0.6369\n",
            "Epoch 6/100\n",
            "17621/17621 [==============================] - 12s 679us/step - loss: 0.8461 - acc: 0.6170 - val_loss: 0.7734 - val_acc: 0.6614\n",
            "Epoch 7/100\n",
            "17621/17621 [==============================] - 13s 723us/step - loss: 0.8364 - acc: 0.6198 - val_loss: 0.7787 - val_acc: 0.6456\n",
            "Epoch 8/100\n",
            "17621/17621 [==============================] - 12s 670us/step - loss: 0.8169 - acc: 0.6371 - val_loss: 0.7585 - val_acc: 0.6701\n",
            "Epoch 9/100\n",
            "17621/17621 [==============================] - 12s 669us/step - loss: 0.7979 - acc: 0.6459 - val_loss: 0.7454 - val_acc: 0.6834\n",
            "Epoch 10/100\n",
            "17621/17621 [==============================] - 12s 670us/step - loss: 0.7894 - acc: 0.6492 - val_loss: 0.7333 - val_acc: 0.6854\n",
            "Epoch 11/100\n",
            "17621/17621 [==============================] - 12s 664us/step - loss: 0.7755 - acc: 0.6602 - val_loss: 0.7164 - val_acc: 0.6961\n",
            "Epoch 12/100\n",
            "17621/17621 [==============================] - 12s 660us/step - loss: 0.7663 - acc: 0.6642 - val_loss: 0.7150 - val_acc: 0.6956\n",
            "Epoch 13/100\n",
            "17621/17621 [==============================] - 12s 706us/step - loss: 0.7542 - acc: 0.6693 - val_loss: 0.7067 - val_acc: 0.6966\n",
            "Epoch 14/100\n",
            "17621/17621 [==============================] - 12s 696us/step - loss: 0.7389 - acc: 0.6796 - val_loss: 0.7103 - val_acc: 0.6920\n",
            "Epoch 15/100\n",
            "17621/17621 [==============================] - 12s 667us/step - loss: 0.7367 - acc: 0.6770 - val_loss: 0.6903 - val_acc: 0.7038\n",
            "Epoch 16/100\n",
            "17621/17621 [==============================] - 12s 660us/step - loss: 0.7287 - acc: 0.6809 - val_loss: 0.6847 - val_acc: 0.7063\n",
            "Epoch 17/100\n",
            "17621/17621 [==============================] - 12s 668us/step - loss: 0.7186 - acc: 0.6861 - val_loss: 0.6942 - val_acc: 0.7038\n",
            "Epoch 18/100\n",
            "17621/17621 [==============================] - 12s 703us/step - loss: 0.7095 - acc: 0.6892 - val_loss: 0.7010 - val_acc: 0.7028\n",
            "Epoch 19/100\n",
            "17621/17621 [==============================] - 12s 661us/step - loss: 0.7013 - acc: 0.6965 - val_loss: 0.6721 - val_acc: 0.7130\n",
            "Epoch 20/100\n",
            "17621/17621 [==============================] - 13s 732us/step - loss: 0.6947 - acc: 0.6998 - val_loss: 0.6866 - val_acc: 0.7099\n",
            "Epoch 21/100\n",
            "17621/17621 [==============================] - 12s 697us/step - loss: 0.6778 - acc: 0.7096 - val_loss: 0.6704 - val_acc: 0.7181\n",
            "Epoch 22/100\n",
            "17621/17621 [==============================] - 12s 664us/step - loss: 0.6784 - acc: 0.7098 - val_loss: 0.6682 - val_acc: 0.7135\n",
            "Epoch 23/100\n",
            "17621/17621 [==============================] - 12s 660us/step - loss: 0.6651 - acc: 0.7160 - val_loss: 0.6601 - val_acc: 0.7186\n",
            "Epoch 24/100\n",
            "17621/17621 [==============================] - 12s 666us/step - loss: 0.6543 - acc: 0.7201 - val_loss: 0.6493 - val_acc: 0.7314\n",
            "Epoch 25/100\n",
            "17621/17621 [==============================] - 12s 666us/step - loss: 0.6501 - acc: 0.7250 - val_loss: 0.6478 - val_acc: 0.7247\n",
            "Epoch 26/100\n",
            "17621/17621 [==============================] - 12s 660us/step - loss: 0.6515 - acc: 0.7224 - val_loss: 0.6499 - val_acc: 0.7314\n",
            "Epoch 27/100\n",
            "17621/17621 [==============================] - 13s 737us/step - loss: 0.6403 - acc: 0.7284 - val_loss: 0.6402 - val_acc: 0.7349\n",
            "Epoch 28/100\n",
            "17621/17621 [==============================] - 12s 677us/step - loss: 0.6368 - acc: 0.7308 - val_loss: 0.6717 - val_acc: 0.7237\n",
            "Epoch 29/100\n",
            "17621/17621 [==============================] - 12s 660us/step - loss: 0.6253 - acc: 0.7357 - val_loss: 0.6435 - val_acc: 0.7385\n",
            "Epoch 30/100\n",
            "17621/17621 [==============================] - 12s 667us/step - loss: 0.6237 - acc: 0.7334 - val_loss: 0.6365 - val_acc: 0.7375\n",
            "Epoch 31/100\n",
            "17621/17621 [==============================] - 12s 708us/step - loss: 0.6160 - acc: 0.7396 - val_loss: 0.6277 - val_acc: 0.7380\n",
            "Epoch 32/100\n",
            "17621/17621 [==============================] - 12s 688us/step - loss: 0.6062 - acc: 0.7442 - val_loss: 0.6377 - val_acc: 0.7375\n",
            "Epoch 33/100\n",
            "17621/17621 [==============================] - 12s 695us/step - loss: 0.5973 - acc: 0.7483 - val_loss: 0.6270 - val_acc: 0.7457\n",
            "Epoch 34/100\n",
            "17621/17621 [==============================] - 12s 706us/step - loss: 0.5979 - acc: 0.7509 - val_loss: 0.6469 - val_acc: 0.7273\n",
            "Epoch 35/100\n",
            "17621/17621 [==============================] - 12s 673us/step - loss: 0.5888 - acc: 0.7514 - val_loss: 0.6219 - val_acc: 0.7451\n",
            "Epoch 36/100\n",
            "17621/17621 [==============================] - 12s 661us/step - loss: 0.5847 - acc: 0.7555 - val_loss: 0.6276 - val_acc: 0.7436\n",
            "Epoch 37/100\n",
            "17621/17621 [==============================] - 12s 686us/step - loss: 0.5840 - acc: 0.7557 - val_loss: 0.6260 - val_acc: 0.7400\n",
            "Epoch 38/100\n",
            "17621/17621 [==============================] - 12s 667us/step - loss: 0.5743 - acc: 0.7599 - val_loss: 0.6249 - val_acc: 0.7477\n",
            "Epoch 39/100\n",
            "17621/17621 [==============================] - 12s 673us/step - loss: 0.5675 - acc: 0.7655 - val_loss: 0.6149 - val_acc: 0.7462\n",
            "Epoch 40/100\n",
            "17621/17621 [==============================] - 13s 735us/step - loss: 0.5682 - acc: 0.7615 - val_loss: 0.6207 - val_acc: 0.7462\n",
            "Epoch 41/100\n",
            "17621/17621 [==============================] - 12s 679us/step - loss: 0.5597 - acc: 0.7707 - val_loss: 0.6227 - val_acc: 0.7569\n",
            "Epoch 42/100\n",
            "17621/17621 [==============================] - 12s 676us/step - loss: 0.5521 - acc: 0.7704 - val_loss: 0.6125 - val_acc: 0.7513\n",
            "Epoch 43/100\n",
            "17621/17621 [==============================] - 13s 727us/step - loss: 0.5494 - acc: 0.7745 - val_loss: 0.6216 - val_acc: 0.7462\n",
            "Epoch 44/100\n",
            "17621/17621 [==============================] - 13s 710us/step - loss: 0.5381 - acc: 0.7765 - val_loss: 0.6221 - val_acc: 0.7472\n",
            "Epoch 45/100\n",
            "17621/17621 [==============================] - 12s 677us/step - loss: 0.5382 - acc: 0.7776 - val_loss: 0.6186 - val_acc: 0.7523\n",
            "Epoch 46/100\n",
            "17621/17621 [==============================] - 13s 755us/step - loss: 0.5284 - acc: 0.7808 - val_loss: 0.6202 - val_acc: 0.7477\n",
            "Epoch 47/100\n",
            "17621/17621 [==============================] - 13s 724us/step - loss: 0.5234 - acc: 0.7819 - val_loss: 0.6221 - val_acc: 0.7503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0797514ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "d37aa7b7-4e47-42ce-b68a-98941f3fbd3e",
        "id": "UZnDuvw8HMwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "score = model.evaluate(x_val_pad, y_val_cat, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6221312910348816\n",
            "Test accuracy: 0.7502553626757964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "792a4e0b-ed59-457a-b391-52bee10089ea",
        "id": "saT4_pNLHMwf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "preds = model.predict(x_val_pad)\n",
        "print(preds[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1559595  0.8405729  0.00346767]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JITtv6vt4cUB"
      },
      "source": [
        "# Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2YlFYD3Jq9F"
      },
      "source": [
        "Swap out the LSTM layer with only densely connected layers. \n",
        "\n",
        "*   How did this affect the accuracy of the model?\n",
        "*   If the performance was worse, why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDG7hePbJe4P"
      },
      "source": [
        "Modify the LSTM model to have 2 hidden RNN layers. \n",
        "\n",
        "*   Did the accuracy of the model improve?\n",
        "*   If not, why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZoJ85ApLcMg"
      },
      "source": [
        "Swap out the LSTM layer with GRU.\n",
        "\n",
        "*   Did the accuracy of the model improve?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDAdddNzbBKV"
      },
      "source": [
        "**Bonus exercise**:\n",
        "\n",
        "Think about a good $f$ function to use as the weight for the GloVe embedding."
      ]
    }
  ]
}